{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.10.10-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.12)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.1.136)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.15.5-cp312-cp312-win_amd64.whl.metadata (63 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.9)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dikshant\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.3 MB/s eta 0:00:00\n",
      "Using cached aiohttp-3.10.10-cp312-cp312-win_amd64.whl (379 kB)\n",
      "Using cached langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.3 MB/s eta 0:00:00\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.15.5-cp312-cp312-win_amd64.whl (85 kB)\n",
      "Using cached propcache-0.2.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Installing collected packages: propcache, numpy, multidict, greenlet, frozenlist, attrs, aiohappyeyeballs, yarl, SQLAlchemy, aiosignal, aiohttp, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 attrs-24.2.0 frozenlist-1.4.1 greenlet-3.1.1 langchain-0.3.4 langchain-text-splitters-0.3.0 multidict-6.1.0 numpy-1.26.4 propcache-0.2.0 yarl-1.15.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-genai\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apr-24', 'May-24', 'Jun-24', 'Jul-24', 'Aug-24', 'Sep-24', 'Dashboard', 'Day Wise 24-25', 'AFR']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file = pd.ExcelFile('UDAAN Initiatives Dashboard (7sep)-7.xlsx')\n",
    "\n",
    "# Get a list of sheet names\n",
    "sheet_names = excel_file.sheet_names\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "\n",
    "# Open the Excel file and specify the sheet and cell\n",
    "wb = xw.Book('Baseline_KPI-1.xlsx')  # This will open the file if not already open\n",
    "result_sheet = wb.sheets['Sheet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_date = result_sheet.range('F2').value\n",
    "end_date = result_sheet.range('G2').value\n",
    "# Define the start and end dates\n",
    "start_date = pd.to_datetime(start_date)\n",
    "end_date = pd.to_datetime(end_date)\n",
    "\n",
    "# Create a list of dates within the range\n",
    "dates = pd.date_range(start_date, end_date)\n",
    "month_names = [date.strftime('%b-%y') for date in dates]\n",
    "unique_month_names = list(set(month_names))\n",
    "unique_month_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aug-24', 'Sep-24']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_month_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_end(month):\n",
    "    month_dict = {'Apr-24': 30, 'May-24': 31, 'Jun-24': 30, 'Jul-24': 31, 'Aug-24': 31, 'Sep-24': 30, 'Oct-24': 31, 'Nov-24': 30, 'Dec-24': 31, 'Jan-25': 31, 'Feb-25': 29, 'Mar-25': 31}\n",
    "    return month_dict[month]+4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific sheet by name\n",
    "def sheet_formatter(sheet_data, month):\n",
    "    start_value = 'PI Addtion in OPC'\n",
    "    end_value = 'Unit 1: Specific Heat'\n",
    "    sheet = pd.DataFrame()\n",
    "    fuel_sheet = pd.DataFrame()\n",
    "    sheet_data = sheet_data.iloc[:, 1:month_end(month)]\n",
    "    new_header = sheet_data.iloc[0]\n",
    "    sheet_data.columns = new_header\n",
    "    sheet_data = sheet_data[1:]\n",
    "    start_index = sheet_data.index[sheet_data['Udaan Initaitives '] == start_value]\n",
    "    end_index = sheet_data.index[sheet_data['Udaan Initaitives '] == end_value]\n",
    "    temp_sheet_data = pd.concat([\n",
    "        sheet_data.iloc[:start_index[0]],\n",
    "        sheet_data.iloc[end_index[0]-1:]], axis=0)\n",
    "    sheet = pd.concat([sheet, temp_sheet_data], axis=0)\n",
    "    sheet = sheet.drop(['Udaan Owner ', 'KPI'],axis=1)\n",
    "    fuel_temp_sheet = sheet_data.iloc[start_index[0]:end_index[0]-1]\n",
    "    fuel_temp_sheet.columns = new_header\n",
    "    fuel_sheet = pd.concat([fuel_sheet, fuel_temp_sheet], axis=1)\n",
    "    fuel_sheet = fuel_sheet.drop(['Udaan Owner ', 'KPI'],axis=1)\n",
    "    return sheet, fuel_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_list = []\n",
    "fuel_sheet_list = []\n",
    "\n",
    "for month in unique_month_names:\n",
    "    sheet_data = pd.read_excel(excel_file, month)\n",
    "    sheet, fuel_sheet = sheet_formatter(sheet_data, month)\n",
    "    sheet.reset_index(drop=True, inplace=True)\n",
    "    fuel_sheet.reset_index(drop=True, inplace=True)\n",
    "    sheet_list.append(sheet)\n",
    "    fuel_sheet_list.append(fuel_sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assumptions = [\"U-I and U-II are the units of the plant\",\n",
    "               \"Imported PC and US Pet Coke are different type of fuel\",\n",
    "               \"If U-I and U-II has same type of fuel then give same name to the fuel type\",\n",
    "               \"PC means Pet Coke\",\n",
    "               \"Imported Petcoke (PC) means Saudi Petcoke\",\n",
    "               \"Don't give python code in response\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(temperature=0.5, model_name=\"llama-3.1-8b-instant\", api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dikshant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.0, api_key=\"AIzaSyCK6q50ZIpIA8UXehU4Sn5xRCoHDPjJhrA\")\n",
    "\n",
    "\n",
    "fuel_prompt=PromptTemplate(\n",
    "            input_variables=[\"fuel_data\", \"assumptions\"],\n",
    "            template=\"\"\"\n",
    "# Fuel Heat Information Extraction\n",
    "\n",
    "## Task Description\n",
    "Extract heat information from text and convert it into a structured format.\n",
    "\n",
    "## Output Format\n",
    "List of dictionaries containing:\n",
    "- `unit`: The operational unit identifier\n",
    "- `fuel_type`: Type of fuel used\n",
    "\n",
    "## Input Structure\n",
    "input_data = [\n",
    "    [\"U-II Imported US Pet Coke %\", \"U-I Total open market coal %\"],\n",
    "    [\"U-I Imported PC %\", \"U-II Indian Coal (Linkage) %\"]\n",
    "]\n",
    "\n",
    "## Expected Output Structure\n",
    "output_data = [\n",
    "    [\n",
    "        {{\"unit\": \"U-II\", \"fuel_type\": \"Imported US Pet Coke\"}},\n",
    "        {{\"unit\": \"U-I\", \"fuel_type\": \"Open Market Coal\"}}\n",
    "    ],\n",
    "    [\n",
    "        {{\"unit\": \"U-I\", \"fuel_type\": \"Saudi Pet Coke\"}},\n",
    "        {{\"unit\": \"U-II\", \"fuel_type\": \"Indian Coal Linkage\"}}\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "Here is the input: \n",
    "{fuel_data}\n",
    "\n",
    "Keep the assumptions in mind while extracting the fuel type:\n",
    "{assumptions}\n",
    "\n",
    "## Notes\n",
    "- Only return the output dictionary in the response\n",
    "- Apply the provided assumptions when extracting fuel types\n",
    "- Maintain the original data structure with nested lists\n",
    "\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "fuel_chain = fuel_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuel_type_extractor(fuel_sheet):\n",
    "    udaan_initiative = fuel_sheet[\"Udaan Initaitives \"]\n",
    "    # udaan_initiative.fillna(\"NA\")\n",
    "    udaan_initiative_lower = udaan_initiative.str.lower()\n",
    "\n",
    "    # Fill NaN values with an empty string to avoid issues with the ~ operator\n",
    "    filtered_row = udaan_initiative_lower[udaan_initiative_lower.fillna('').str.contains(r'\\bheat\\b', case=False) & \n",
    "            ~udaan_initiative_lower.fillna('').str.contains(r'\\bTotal Heat\\b', case=False) & \n",
    "            ~udaan_initiative_lower.fillna('').str.contains(r'\\bSpecific Heat\\b', case=False)]\n",
    "\n",
    "    fuel_sheet_cleaned = pd.DataFrame(columns=fuel_sheet.columns)\n",
    "    fuel_type_list = []\n",
    "    for i in filtered_row.index:\n",
    "        fuel_data = fuel_sheet['Udaan Initaitives '][i+1]\n",
    "        fuel_type_list.append(fuel_data)\n",
    "        fuel_sheet_cleaned = pd.concat([fuel_sheet_cleaned, fuel_sheet.iloc[[i]]], ignore_index=True)\n",
    "        \n",
    "    return fuel_type_list, fuel_sheet_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_type_list = []\n",
    "fuel_heat_row_list = []\n",
    "for fuel_sheet in fuel_sheet_list:\n",
    "    fuel_type, fuel_heat_row = fuel_type_extractor(fuel_sheet)\n",
    "    fuel_type_list.append(fuel_type)\n",
    "    fuel_heat_row_list.append(fuel_heat_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'unit': 'U-II', 'fuel_type': 'Imported US Pet Coke'},\n",
       "  {'unit': 'U-II', 'fuel_type': 'Indian Coal Linkage'},\n",
       "  {'unit': 'U-II', 'fuel_type': 'Open Market Coal'},\n",
       "  {'unit': 'U-I', 'fuel_type': 'Saudi Pet Coke'},\n",
       "  {'unit': 'U-I', 'fuel_type': 'Indian Coal Linkage'},\n",
       "  {'unit': 'U-I', 'fuel_type': 'Open Market Coal'}],\n",
       " [{'unit': 'U-II', 'fuel_type': 'Imported US Pet Coke'},\n",
       "  {'unit': 'U-II', 'fuel_type': 'Indian Coal Linkage'},\n",
       "  {'unit': 'U-II', 'fuel_type': 'Open Market Coal'},\n",
       "  {'unit': 'U-II', 'fuel_type': 'Indian Pet Coke'},\n",
       "  {'unit': 'U-I', 'fuel_type': 'Saudi Pet Coke'},\n",
       "  {'unit': 'U-I', 'fuel_type': 'Indian Coal Linkage'},\n",
       "  {'unit': 'U-I', 'fuel_type': 'Open Market Coal'}]]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = fuel_chain.invoke({\"fuel_data\": fuel_type_list, \"assumptions\": assumptions})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuel_sheet_updater(fuel_sheet, result):\n",
    "    modified_row = []\n",
    "    for i, row in fuel_sheet.iterrows():\n",
    "        modified_row.append(f'{result[i]['unit']}_{result[i]['fuel_type']}_Heat')\n",
    "        fuel_sheet.loc[i, 'Udaan Initaitives '] = f'{result[i]['unit']}_{result[i]['fuel_type']}_Heat'\n",
    "    return modified_row, fuel_sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_df_cleaned = []\n",
    "modified_row_list = []\n",
    "for i, fuel_sheet in enumerate(fuel_heat_row_list):\n",
    "    modified_row, fuel_sheet_cleaned = fuel_sheet_updater(fuel_sheet, result[i])\n",
    "    modified_row_list.append(modified_row)\n",
    "    fuel_df_cleaned.append(fuel_sheet_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Udaan Initaitives</th>\n",
       "      <th>2024-08-01 00:00:00</th>\n",
       "      <th>2024-08-02 00:00:00</th>\n",
       "      <th>2024-08-03 00:00:00</th>\n",
       "      <th>2024-08-04 00:00:00</th>\n",
       "      <th>2024-08-05 00:00:00</th>\n",
       "      <th>2024-08-06 00:00:00</th>\n",
       "      <th>2024-08-07 00:00:00</th>\n",
       "      <th>2024-08-08 00:00:00</th>\n",
       "      <th>2024-08-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2024-08-22 00:00:00</th>\n",
       "      <th>2024-08-23 00:00:00</th>\n",
       "      <th>2024-08-24 00:00:00</th>\n",
       "      <th>2024-08-25 00:00:00</th>\n",
       "      <th>2024-08-26 00:00:00</th>\n",
       "      <th>2024-08-27 00:00:00</th>\n",
       "      <th>2024-08-28 00:00:00</th>\n",
       "      <th>2024-08-29 00:00:00</th>\n",
       "      <th>2024-08-30 00:00:00</th>\n",
       "      <th>2024-08-31 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U-II_Imported US Pet Coke_Heat</td>\n",
       "      <td>2357936</td>\n",
       "      <td>3144595</td>\n",
       "      <td>2264879.94</td>\n",
       "      <td>2254378</td>\n",
       "      <td>2498184</td>\n",
       "      <td>2571403</td>\n",
       "      <td>2545920</td>\n",
       "      <td>2786350</td>\n",
       "      <td>2649348</td>\n",
       "      <td>...</td>\n",
       "      <td>1472785</td>\n",
       "      <td>2275416</td>\n",
       "      <td>2651013</td>\n",
       "      <td>2617524</td>\n",
       "      <td>2875726</td>\n",
       "      <td>3068835</td>\n",
       "      <td>3035046</td>\n",
       "      <td>3057024</td>\n",
       "      <td>3003182</td>\n",
       "      <td>3000856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U-II_Indian Coal Linkage_Heat</td>\n",
       "      <td>881575</td>\n",
       "      <td>1613796</td>\n",
       "      <td>2050297.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2931672</td>\n",
       "      <td>2703068</td>\n",
       "      <td>2638620</td>\n",
       "      <td>2728482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U-II_Open Market Coal_Heat</td>\n",
       "      <td>2117435</td>\n",
       "      <td>1375980</td>\n",
       "      <td>0</td>\n",
       "      <td>2103546</td>\n",
       "      <td>2660112</td>\n",
       "      <td>2827005</td>\n",
       "      <td>3176768</td>\n",
       "      <td>2981208</td>\n",
       "      <td>3022784</td>\n",
       "      <td>...</td>\n",
       "      <td>1975536</td>\n",
       "      <td>2778722</td>\n",
       "      <td>3283256</td>\n",
       "      <td>3226368</td>\n",
       "      <td>2740300</td>\n",
       "      <td>2637120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U-I_Saudi Pet Coke_Heat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U-I_Indian Coal Linkage_Heat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5103648</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U-I_Open Market Coal_Heat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2876760</td>\n",
       "      <td>5033528</td>\n",
       "      <td>5158800</td>\n",
       "      <td>5169078</td>\n",
       "      <td>5228074</td>\n",
       "      <td>5123295</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0              Udaan Initaitives  2024-08-01 00:00:00 2024-08-02 00:00:00  \\\n",
       "0  U-II_Imported US Pet Coke_Heat             2357936             3144595   \n",
       "1   U-II_Indian Coal Linkage_Heat              881575             1613796   \n",
       "2      U-II_Open Market Coal_Heat             2117435             1375980   \n",
       "3         U-I_Saudi Pet Coke_Heat                   0                   0   \n",
       "4    U-I_Indian Coal Linkage_Heat                   0                   0   \n",
       "5       U-I_Open Market Coal_Heat                   0                   0   \n",
       "\n",
       "0 2024-08-03 00:00:00 2024-08-04 00:00:00 2024-08-05 00:00:00  \\\n",
       "0          2264879.94             2254378             2498184   \n",
       "1          2050297.08                   0                   0   \n",
       "2                   0             2103546             2660112   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "5             2876760             5033528             5158800   \n",
       "\n",
       "0 2024-08-06 00:00:00 2024-08-07 00:00:00 2024-08-08 00:00:00  \\\n",
       "0             2571403             2545920             2786350   \n",
       "1                   0                   0                   0   \n",
       "2             2827005             3176768             2981208   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "5             5169078             5228074             5123295   \n",
       "\n",
       "0 2024-08-09 00:00:00  ... 2024-08-22 00:00:00 2024-08-23 00:00:00  \\\n",
       "0             2649348  ...             1472785             2275416   \n",
       "1                   0  ...                   0                   0   \n",
       "2             3022784  ...             1975536             2778722   \n",
       "3                   0  ...                   0                   0   \n",
       "4             5103648  ...                   0                   0   \n",
       "5                   0  ...                   0                   0   \n",
       "\n",
       "0 2024-08-24 00:00:00 2024-08-25 00:00:00 2024-08-26 00:00:00  \\\n",
       "0             2651013             2617524             2875726   \n",
       "1                   0                   0                   0   \n",
       "2             3283256             3226368             2740300   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "5                   0                   0                   0   \n",
       "\n",
       "0 2024-08-27 00:00:00 2024-08-28 00:00:00 2024-08-29 00:00:00  \\\n",
       "0             3068835             3035046             3057024   \n",
       "1                   0             2931672             2703068   \n",
       "2             2637120                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "5                   0                   0                   0   \n",
       "\n",
       "0 2024-08-30 00:00:00 2024-08-31 00:00:00  \n",
       "0             3003182             3000856  \n",
       "1             2638620             2728482  \n",
       "2                   0                   0  \n",
       "3                   0                   0  \n",
       "4                   0                   0  \n",
       "5                   0                   0  \n",
       "\n",
       "[6 rows x 32 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel_df_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sheet = sheet_list[0]\n",
    "for sheet in sheet_list[1:]:\n",
    "    merged_sheet = pd.merge(merged_sheet, sheet, on='Udaan Initaitives ', how='outer')\n",
    "merged_fuel_sheet = fuel_df_cleaned[0]\n",
    "for fuel_sheet in fuel_df_cleaned[1:]:\n",
    "    merged_fuel_sheet = pd.merge(merged_fuel_sheet, fuel_sheet, on='Udaan Initaitives ', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_types_prompt=PromptTemplate(\n",
    "            input_variables=[\"fuel_types\", \"assumptions\"],\n",
    "            template=\"\"\"\n",
    "            Group the same type of fuel together and give them common name. Give output in JSON format\n",
    "\n",
    "            Example input: [\"U-II_Imported US Pet Coke_Heat\", \"U-II_Indian Coal (Linkage)_Heat\", \"U-II_open market coal_Heat\", \"U-I_Imported PC_Heat\", \"U-I_Indian Coal Linkage_Heat\", \"U-I_Open market coal_Heat\"]\n",
    "\n",
    "            Example output: [\"US Pet Coke\", \"Linkage Coal\", \"Open Mkt Coal\", \"Imported Pet Coke\", \"Linkage Coal\", \"Open Mkt Coal\"]\n",
    "\n",
    "\n",
    "            Here is the input: \n",
    "            {fuel_types}\n",
    "\n",
    "            Keep the assumptions in mind while grouping the fuel types:\n",
    "            {assumptions}\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "fuel_types_chain = fuel_types_prompt | llm | JsonOutputParser()\n",
    "\n",
    "merged_fuel_sheet_list = merged_fuel_sheet[\"Udaan Initaitives \"]\n",
    "classified_fuel = fuel_types_chain.invoke({\"fuel_types\": merged_fuel_sheet_list, \"assumptions\": assumptions})\n",
    "\n",
    "fuel_type_dict = {}\n",
    "for i in range(len(classified_fuel)):\n",
    "    key = classified_fuel[i]\n",
    "    value = merged_fuel_sheet_list[i]\n",
    "    if key in fuel_type_dict:\n",
    "        fuel_type_dict[key].append(value)\n",
    "    else:\n",
    "        fuel_type_dict[key] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Imported US Pet Coke': ['U-II_Imported US Pet Coke_Heat'],\n",
       " 'Linkage Coal': ['U-II_Indian Coal Linkage_Heat',\n",
       "  'U-I_Indian Coal Linkage_Heat'],\n",
       " 'Indian Pet Coke': ['U-II_Indian Pet Coke_Heat'],\n",
       " 'Open Mkt Coal': ['U-II_Open Market Coal_Heat', 'U-I_Open Market Coal_Heat'],\n",
       " 'Imported Pet Coke': ['U-I_Saudi Pet Coke_Heat']}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel_type_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sheet = merged_sheet.dropna(subset=['Udaan Initaitives '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sheet.to_excel('merged_sheet1.xlsx', index=False)\n",
    "merged_fuel_sheet.to_excel('merged_fuel_sheet1.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dikshant\\AppData\\Local\\Temp\\ipykernel_76740\\2643634228.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  merged_sheet = merged_sheet.applymap(replace_hyphen)\n",
      "C:\\Users\\Dikshant\\AppData\\Local\\Temp\\ipykernel_76740\\2643634228.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  merged_fuel_sheet = merged_fuel_sheet.applymap(replace_hyphen)\n"
     ]
    }
   ],
   "source": [
    "# Function to replace hyphens with 0, but only if they are standalone hyphens\n",
    "def replace_hyphen(val):\n",
    "    if isinstance(val, str) and val.strip() == '-':  # Check if it's a string and only a hyphen\n",
    "        return 0  # Replace with 0\n",
    "    return val  # Return the value as is if it's not a standalone hyphen\n",
    "\n",
    "# Apply this function to the entire DataFrame\n",
    "merged_sheet = merged_sheet.applymap(replace_hyphen)\n",
    "merged_fuel_sheet = merged_fuel_sheet.applymap(replace_hyphen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sheet.to_excel('merged_sheet_cleaned.xlsx', index=False)\n",
    "merged_fuel_sheet.to_excel('merged_fuel_sheet_cleaned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_range = merged_sheet[\"Udaan Initaitives \"]\n",
    "fuel_range = merged_fuel_sheet[\"Udaan Initaitives \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_range = {name: i for i, name in enumerate(named_range)}\n",
    "fuel_range = {name: i for i, name in enumerate(fuel_range)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = merged_sheet\n",
    "fuel_sheet = merged_fuel_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dikshant\\AppData\\Local\\Temp\\ipykernel_76740\\588205745.py:137: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  sum_line1_whrs_gen = sum(line1_whrs_gen[i] for i in range(len(clinker_prod_U1)) if clinker_prod_U1[i] > clinker_lower_limit_line1)\n",
      "C:\\Users\\Dikshant\\AppData\\Local\\Temp\\ipykernel_76740\\588205745.py:148: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  sum_line2_whrs_gen = sum(line2_whrs_gen[i] for i in range(len(clinker_prod_U2)) if clinker_prod_U2[i] > clinker_lower_limit_line2)\n"
     ]
    }
   ],
   "source": [
    "def safe_product(a, b):\n",
    "    return a/b if b != 0 else 0\n",
    "\n",
    "sum_cement_prod_ppc = sheet.loc[named_range['Cement Production (PPC)'], dates].sum(axis=0)\n",
    "\n",
    "sum_flyash_ppc = sheet.loc[named_range['Actual fly ash consumption (PPC)'], dates].sum(axis=0)\n",
    "\n",
    "incr_flyash_ppc = safe_product(sum_flyash_ppc, sum_cement_prod_ppc)\n",
    "\n",
    "sum_cement_prod_dt = sheet.loc[named_range['Cement Production (DT)'], dates].sum(axis=0)\n",
    "\n",
    "sum_flyash_dt = sheet.loc[named_range['Actual fly ash consumption (DT)'], dates].sum(axis=0)\n",
    "\n",
    "incr_flyash_dt = safe_product(sum_flyash_dt, sum_cement_prod_dt)\n",
    "\n",
    "sum_cement_prod_aw = sheet.loc[named_range['Cement Production (AW)'], dates].sum(axis=0)\n",
    "\n",
    "sum_flyash_aw = sheet.loc[named_range['Actual fly ash consumption (AW)'], dates].sum(axis=0)\n",
    "\n",
    "incr_flyash_aw = safe_product(sum_flyash_aw, sum_cement_prod_aw)\n",
    "\n",
    "sum_fgd_gypsum = sheet.loc[named_range['FGD Gypsum'], dates].sum(axis=0)\n",
    "\n",
    "sum_bed_ash_gypsum = sheet.loc[named_range['Bed Ash Gypsum'], dates].sum(axis=0)\n",
    "\n",
    "sum_natural_gypsum_unit1 = sheet.loc[named_range['Natural Gypsum (Unit-I)'], dates].sum(axis=0)\n",
    "\n",
    "sum_natural_gypsum_unit2 = sheet.loc[named_range['Natural Gypsum (Unit-II)'], dates].sum(axis=0)\n",
    "\n",
    "sum_natural_gypsum_activated_gypsum = sheet.loc[named_range['Natural Gypsum in Activated Gypsum'], dates].sum(axis=0)\n",
    "\n",
    "sum_limestone_activated_gypsum = sheet.loc[named_range['Limestone in Activated Gypsum'], dates].sum(axis=0)\n",
    "\n",
    "sum_total_gypsum_usage = sheet.loc[named_range['Total gypsum usage'], dates].sum(axis=0)\n",
    "\n",
    "alternate_gypsum_usage = safe_product(sum_fgd_gypsum+sum_bed_ash_gypsum+sum_limestone_activated_gypsum, sum_total_gypsum_usage)\n",
    "\n",
    "sum_conditioned_ash_used = sheet.loc[named_range['Conditioned Ash used'], dates].sum(axis=0)\n",
    "\n",
    "sum_total_flyash_used = sheet.loc[named_range['Total Fly Ash used'], dates].sum(axis=0)\n",
    "\n",
    "conditioned_ash_usage = safe_product(sum_conditioned_ash_used, sum_total_flyash_used)\n",
    "\n",
    "sum_total_opc_production = sheet.loc[named_range['Total OPC Production'], dates].sum(axis=0)\n",
    "\n",
    "sum_pi_addition = sheet.loc[named_range['PI Addition'], dates].sum(axis=0)\n",
    "\n",
    "pi_addition_opc = safe_product(sum_pi_addition, sum_total_opc_production)\n",
    "\n",
    "# sum_imported_us_pc = sheet.loc[named_range['U-II Imported US Pet Coke'], dates].sum(axis=0)\n",
    "\n",
    "# product_imported_us_pc_cv = sheet.loc[named_range['U-II Imported US Pet Coke'], dates]*sheet.loc[named_range['U-II Imported US Pet Coke CV'], dates]\n",
    "\n",
    "# avg_imported_us_pc_cv = safe_product(product_imported_us_pc_cv.sum(axis=0), sum_imported_us_pc)\n",
    "\n",
    "# sum_total_heat_unit2 = sheet.loc[named_range['U-II Total Heat'], dates].sum(axis=0)\n",
    "\n",
    "# sum_imported_us_pc_heat = sheet.loc[named_range['U-II Imported US PC Heat'], dates].sum(axis=0)\n",
    "\n",
    "# percentage_imported_us_pc_heat = safe_product(sum_imported_us_pc_heat, sum_total_heat_unit2)\n",
    "\n",
    "# linkage_coal_unit2 = sheet.loc[named_range['U-II Indian Coal (Linkage)'], dates].sum(axis=0)\n",
    "\n",
    "# product_linkage_coal_unit2_cv = sheet.loc[named_range['U-II Indian Coal (Linkage)'], dates]*sheet.loc[named_range['U-II Indian Coal (Linkage) CV'], dates]\n",
    "\n",
    "# avg_linkage_coal_unit2_cv = safe_product(product_linkage_coal_unit2_cv.sum(axis=0), linkage_coal_unit2)\n",
    "\n",
    "# sum_total_heat_linkage_coal_unit2 = sheet.loc[named_range['U-II Indian Coal (Linkage) Heat'], dates].sum(axis=0)\n",
    "\n",
    "# percentage_linkage_coal_unit2 = safe_product(sum_total_heat_linkage_coal_unit2, sum_total_heat_unit2)\n",
    "\n",
    "# open_mkt_coal_unit2 = sheet.loc[named_range['U-II Open market coal (by road) qty'], dates].sum(axis=0)\n",
    "\n",
    "# product_open_mkt_coal_unit2_cv = sheet.loc[named_range['U-II Open market coal (by road) CV'], dates]*sheet.loc[named_range['U-II Open market coal (by road) qty'], dates]\n",
    "\n",
    "# avg_open_mkt_coal_unit2_cv = safe_product(product_open_mkt_coal_unit2_cv.sum(axis=0), open_mkt_coal_unit2)\n",
    "\n",
    "# sum_total_heat_open_mkt_coal_unit2 = sheet.loc[named_range['U-II Open market coal (by road) heat'], dates].sum(axis=0)\n",
    "\n",
    "# percentage_open_mkt_coal_unit2 = safe_product(sum_total_heat_open_mkt_coal_unit2, sum_total_heat_unit2)\n",
    "\n",
    "# sum_imported_pc_unit1 = sheet.loc[named_range['U-I Imported PC Quantity'], dates].sum(axis=0)\n",
    "\n",
    "# product_imported_pc_unit1_cv = sheet.loc[named_range['U-I Imported PC Quantity'], dates]*sheet.loc[named_range['U-I Imported PC CV'], dates]\n",
    "\n",
    "# avg_imported_pc_unit1_cv = safe_product(product_imported_pc_unit1_cv.sum(axis=0), sum_imported_pc_unit1)\n",
    "\n",
    "# sum_imported_pc_heat_unit1 = sheet.loc[named_range['U-I Imported PC Heat'], dates].sum(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# percentage_imported_pc_unit1 = safe_product(sum_imported_pc_heat_unit1, sum_total_heat_unit1)\n",
    "\n",
    "# linkage_coal_unit1 = sheet.loc[named_range['U-I Indian Coal Linkage'], dates].sum(axis=0)\n",
    "\n",
    "# product_linkage_coal_unit1_cv = sheet.loc[named_range['U-I Indian Coal Linkage'], dates]*sheet.loc[named_range['U-I Indian Coal Linkage CV'], dates]\n",
    "\n",
    "# avg_linkage_coal_unit1_cv = safe_product(product_linkage_coal_unit1_cv.sum(axis=0), linkage_coal_unit1)\n",
    "\n",
    "# sum_heat_linkage_coal_heat_unit1 = sheet.loc[named_range['U-I Indian Coal Linkage Heat'], dates].sum(axis=0)\n",
    "\n",
    "# percentage_linkage_coal_unit1 = safe_product(sum_heat_linkage_coal_heat_unit1, sum_total_heat_unit1)\n",
    "\n",
    "# sum_open_mkt_coal_unit1 = sheet.loc[named_range['U-I Open market coal (by road) qty'], dates].sum(axis=0)\n",
    "\n",
    "# product_open_mkt_coal_unit1_cv = sheet.loc[named_range['U-I Open market coal (by road) qty'], dates]*sheet.loc[named_range['U-I Open market coal (by road) CV'], dates]\n",
    "\n",
    "# avg_open_mkt_coal_unit1_cv = safe_product(product_open_mkt_coal_unit1_cv.sum(axis=0), sum_open_mkt_coal_unit1)\n",
    "\n",
    "# sum_open_mkt_coal_heat_unit1 = sheet.loc[named_range['U-I Open market coal (by road) heat'], dates].sum(axis=0)\n",
    "\n",
    "# percentage_open_mkt_coal_unit1 = safe_product(sum_open_mkt_coal_heat_unit1, sum_total_heat_unit1)\n",
    "clinker_prod_U1 = sheet.loc[named_range['Unit-1 Clinker Production'], dates]\n",
    "specific_heat_U1 = sheet.loc[named_range['Unit 1: Specific Heat'], dates]\n",
    "sum_total_heat_unit1 = (sheet.loc[named_range['Unit-1 Clinker Production'], dates] * \n",
    "                                sheet.loc[named_range['Unit 1: Specific Heat'], dates]).sum(axis=0)\n",
    "\n",
    "clinker_prod_U2 = sheet.loc[named_range['Unit-2 Clinker Production'], dates]\n",
    "specific_heat_U2 = sheet.loc[named_range['Unit 2: Specific Heat'], dates]\n",
    "sum_total_heat_unit2 = (sheet.loc[named_range['Unit-2 Clinker Production'], dates] * \n",
    "                                sheet.loc[named_range['Unit 2: Specific Heat'], dates]).sum(axis=0)\n",
    "\n",
    "sum_clinker_prod_U1 = sheet.loc[named_range['Unit-1 Clinker Production'], dates].sum(axis=0)\n",
    "\n",
    "avg_unit1_specific_heat = safe_product(sum_total_heat_unit1, sum_clinker_prod_U1)\n",
    "\n",
    "sum_clinker_prod_U2 = sheet.loc[named_range['Unit-2 Clinker Production'], dates].sum(axis=0)\n",
    "\n",
    "avg_unit2_specific_heat = safe_product(sum_total_heat_unit2, sum_clinker_prod_U2)\n",
    "\n",
    "\n",
    "# ------------------------------------------WHRS--------------------------------------------\n",
    "\n",
    "line1_whrs_gen = sheet.loc[named_range['Line1 WHRS Generation'], dates]\n",
    "clinker_prod_U1 = sheet.loc[named_range['Unit-1 Clinker Production'], dates]\n",
    "clinker_lower_limit_line1 = 5950\n",
    "sum_line1_whrs_gen = sum(line1_whrs_gen[i] for i in range(len(clinker_prod_U1)) if clinker_prod_U1[i] > clinker_lower_limit_line1)\n",
    "\n",
    "\n",
    "kiln1_whrs_gen = safe_product(sum_line1_whrs_gen, sum_clinker_prod_U1)\n",
    "\n",
    "\n",
    "line2_whrs_gen = sheet.loc[named_range['Line2 WHRS Generation'], dates]\n",
    "\n",
    "clinker_prod_U2 = sheet.loc[named_range['Unit-2 Clinker Production'], dates]\n",
    "\n",
    "clinker_lower_limit_line2 = 7905\n",
    "sum_line2_whrs_gen = sum(line2_whrs_gen[i] for i in range(len(clinker_prod_U2)) if clinker_prod_U2[i] > clinker_lower_limit_line2)\n",
    "\n",
    "\n",
    "kiln2_whrs_gen = safe_product(sum_line2_whrs_gen, sum_clinker_prod_U2)\n",
    "\n",
    "sum_whrs_gross_gen = sheet.loc[named_range['WHRS Gross generation'], dates].sum(axis=0)\n",
    "\n",
    "sum_kiln1_and_2_whrs_gen = safe_product(sum_whrs_gross_gen, (sum_clinker_prod_U1+sum_clinker_prod_U2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Solid AFR NCV ARB using Solid AFR feeding and Solid AFR NCV ARB\n",
    "solid_afr_ncv_arb_sumproduct = (sheet.loc[named_range['Solid AFR feeding'], dates] * \n",
    "                                sheet.loc[named_range['Solid AFR NCV ADB'], dates]).sum(axis=0)\n",
    "\n",
    "# 2. U-I Liquid AFR CV using U-I Liquid AFR (LCV) tons and U-I Liquid AFR CV\n",
    "ui_liquid_afr_lcv_sumproduct = (sheet.loc[named_range['U-I Liquid AFR (LCV) tons'], dates] * \n",
    "                               sheet.loc[named_range['U-I Liquid AFR CV'], dates]).sum(axis=0)\n",
    "\n",
    "ui_liquid_afr_hcv_sumproduct = (sheet.loc[named_range['U-I Liquid AFR (HCV) tons'], dates] * \n",
    "                               sheet.loc[named_range['U-I Liquid AFR CV'], dates]).sum(axis=0)\n",
    "\n",
    "# 3. U-II Liquid AFR CV using U-II Liquid AFR (LCV) tons and U-II Liquid AFR CV\n",
    "uii_liquid_afr_lcv_sumproduct = (sheet.loc[named_range['U-II Liquid AFR (LCV) tons'], dates] * \n",
    "                                sheet.loc[named_range['U-II Liquid AFR CV'], dates]).sum(axis=0)\n",
    "\n",
    "\n",
    "uii_liquid_afr_hcv_sumproduct = (sheet.loc[named_range['U-II Liquid AFR (HCV) tons'], dates] * \n",
    "                                sheet.loc[named_range['U-II Liquid AFR CV'], dates]).sum(axis=0)\n",
    "\n",
    "\n",
    "# 4. Rehandling using Total feeding and Rehandling\n",
    "rehandling_sumproduct = (sheet.loc[named_range['Total feeding'], dates] * \n",
    "                         sheet.loc[named_range['Rehandling'], dates]).sum(axis=0)\n",
    "\n",
    "# 5. Sweetener using Total feeding and Sweetener\n",
    "sweetener_sumproduct = (sheet.loc[named_range['Total feeding'], dates] * \n",
    "                        sheet.loc[named_range['Sweetener'], dates]).sum(axis=0)\n",
    "\n",
    "# 6. Purchase using Total feeding and Purchase\n",
    "purchase_sumproduct = (sheet.loc[named_range['Total feeding'], dates] * \n",
    "                       sheet.loc[named_range['Purchase'], dates]).sum(axis=0)\n",
    "\n",
    "# 1. Solid AFR NCV ARB: weighted average using Solid AFR feeding and Solid AFR NCV ARB\n",
    "solid_afr_feeding_total = sheet.loc[named_range['Solid AFR feeding'], dates].sum(axis=0)\n",
    "solid_afr_ncv_arb_weighted_avg = safe_product(solid_afr_ncv_arb_sumproduct, solid_afr_feeding_total)\n",
    "\n",
    "# 2. U-I Liquid AFR CV: weighted average using U-I Liquid AFR (LCV) tons and U-I Liquid AFR CV\n",
    "ui_liquid_afr_hcv_tons_total = sheet.loc[named_range['U-I Liquid AFR (HCV) tons'], dates].sum(axis=0)\n",
    "ui_liquid_afr_lcv_tons_total = sheet.loc[named_range['U-I Liquid AFR (LCV) tons'], dates].sum(axis=0)\n",
    "ui_liquid_afr_hcv_weighted_avg = safe_product(ui_liquid_afr_hcv_sumproduct, ui_liquid_afr_hcv_tons_total)\n",
    "ui_liquid_afr_lcv_weighted_avg = safe_product(ui_liquid_afr_lcv_sumproduct, ui_liquid_afr_lcv_tons_total)\n",
    "\n",
    "# 3. U-II Liquid AFR CV: weighted average using U-II Liquid AFR (LCV) tons and U-II Liquid AFR CV\n",
    "uii_liquid_afr_hcv_tons_total = sheet.loc[named_range['U-II Liquid AFR (HCV) tons'], dates].sum(axis=0)\n",
    "uii_liquid_afr_lcv_tons_total = sheet.loc[named_range['U-II Liquid AFR (LCV) tons'], dates].sum(axis=0)\n",
    "uii_liquid_afr_hcv_weighted_avg = safe_product(uii_liquid_afr_hcv_sumproduct, uii_liquid_afr_hcv_tons_total)\n",
    "uii_liquid_afr_lcv_weighted_avg = safe_product(uii_liquid_afr_lcv_sumproduct, uii_liquid_afr_lcv_tons_total)\n",
    "\n",
    "# 4. Rehandling: weighted average using Total feeding and Rehandling\n",
    "total_feeding_rehandling = sheet.loc[named_range['Total feeding'], dates].sum(axis=0)\n",
    "rehandling_weighted_avg = safe_product(rehandling_sumproduct , total_feeding_rehandling)\n",
    "\n",
    "# 5. Sweetener: weighted average using Total feeding and Sweetener\n",
    "total_feeding_sweetener = sheet.loc[named_range['Total feeding'], dates].sum(axis=0)\n",
    "sweetener_weighted_avg = safe_product(sweetener_sumproduct , total_feeding_sweetener)\n",
    "\n",
    "# 6. Purchase: weighted average using Total feeding and Purchase\n",
    "total_feeding_purchase = sheet.loc[named_range['Total feeding'], dates].sum(axis=0)\n",
    "purchase_weighted_avg = safe_product(purchase_sumproduct , total_feeding_purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Solid AFR feeding\n",
    "sum_solid_afr_feeding = sheet.loc[named_range['Solid AFR feeding'], dates].sum(axis=0)\n",
    "\n",
    "# 2. Line 1 Cement: Champion\n",
    "sum_line1_cement_champion = sheet.loc[named_range['Line 1 Cement: Champion'], dates].sum(axis=0)\n",
    "\n",
    "# 3. Line 1 Cement: Champion +\n",
    "sum_line1_cement_champion_plus = sheet.loc[named_range['Line 1 Cement: Champion +'], dates].sum(axis=0)\n",
    "\n",
    "# 4. Line 1 Cement: Duratech\n",
    "sum_line1_cement_duratech = sheet.loc[named_range['Line 1 Cement: Duratech'], dates].sum(axis=0)\n",
    "\n",
    "# 5. Line 1 Cement: All Weather\n",
    "sum_line1_cement_all_weather = sheet.loc[named_range['Line 1 Cement: All Weather'], dates].sum(axis=0)\n",
    "\n",
    "# 6. Line 1 Cement: OPC\n",
    "sum_line1_cement_opc = sheet.loc[named_range['Line 1 Cement: OPC'], dates].sum(axis=0)\n",
    "\n",
    "# 7. Line 2 Cement: Champion\n",
    "sum_line2_cement_champion = sheet.loc[named_range['Line 2 Cement: Champion'], dates].sum(axis=0)\n",
    "\n",
    "# 8. Line 2 Cement: Champion +\n",
    "sum_line2_cement_champion_plus = sheet.loc[named_range['Line 2 Cement: Champion +'], dates].sum(axis=0)\n",
    "\n",
    "# 9. Line 2 Cement: OPC\n",
    "sum_line2_cement_opc = sheet.loc[named_range['Line 2 Cement: OPC'], dates].sum(axis=0)\n",
    "\n",
    "# 10. Total Cement Production (MT)\n",
    "sum_total_cement_production = sheet.loc[named_range['Total Cement Production (MT)'], dates].sum(axis=0)\n",
    "\n",
    "# 11. Line 1 Cement: Champion (FA)\n",
    "sum_line1_cement_champion_fa = sheet.loc[named_range['Line 1 Cement: Champion (FA)'], dates].sum(axis=0)\n",
    "\n",
    "# 12. Line 1 Cement: Champion + (FA)\n",
    "sum_line1_cement_champion_plus_fa = sheet.loc[named_range['Line 1 Cement: Champion + (FA)'], dates].sum(axis=0)\n",
    "\n",
    "# 13. Line 1 Cement: Duratech (FA)\n",
    "sum_line1_cement_duratech_fa = sheet.loc[named_range['Line 1 Cement: Duratech (FA)'], dates].sum(axis=0)\n",
    "\n",
    "# 14. Line 1 Cement: All Weather (FA)\n",
    "sum_line1_cement_all_weather_fa = sheet.loc[named_range['Line 1 Cement: All Weather (FA)'], dates].sum(axis=0)\n",
    "\n",
    "# 15. Line 2 Cement: Champion (FA)\n",
    "sum_line2_cement_champion_fa = sheet.loc[named_range['Line 2 Cement: Champion (FA)'], dates].sum(axis=0)\n",
    "\n",
    "# 16. Line 2 Cement: Champion + (FA)\n",
    "sum_line2_cement_champion_plus_fa = sheet.loc[named_range['Line 2 Cement: Champion + (FA)'], dates].sum(axis=0)\n",
    "\n",
    "# 17. Line 1 Cement: OPC PI\n",
    "sum_line1_cement_opc_pi = sheet.loc[named_range['Line 1 Cement: OPC PI'], dates].sum(axis=0)\n",
    "\n",
    "# 18. Line 2 Cement: OPC PI\n",
    "sum_line2_cement_opc_pi = sheet.loc[named_range['Line 2 Cement: OPC PI'], dates].sum(axis=0)\n",
    "\n",
    "# 19. U-I Liquid AFR (LCV) tons\n",
    "sum_ui_liquid_afr_lcv_tons = sheet.loc[named_range['U-I Liquid AFR (LCV) tons'], dates].sum(axis=0)\n",
    "\n",
    "# 20. U-I Liquid AFR (HCV) tons\n",
    "sum_ui_liquid_afr_hcv_tons = sheet.loc[named_range['U-I Liquid AFR (HCV) tons'], dates].sum(axis=0)\n",
    "\n",
    "# 21. U-II Liquid AFR (LCV) tons\n",
    "sum_uii_liquid_afr_lcv_tons = sheet.loc[named_range['U-II Liquid AFR (LCV) tons'], dates].sum(axis=0)\n",
    "\n",
    "# 22. U-II Liquid AFR (HCV) tons\n",
    "sum_uii_liquid_afr_hcv_tons = sheet.loc[named_range['U-II Liquid AFR (HCV) tons'], dates].sum(axis=0)\n",
    "\n",
    "# 23. U-I Natural Gypsum in Activated Gypsum\n",
    "sum_ui_natural_gypsum = sheet.loc[named_range['U-I Natural Gypsum in Activated Gypsum'], dates].sum(axis=0)\n",
    "\n",
    "# 24. U-I Limestone in Activated Gypsum\n",
    "sum_ui_limestone_gypsum = sheet.loc[named_range['U-I Limestone in Activated Gypsum'], dates].sum(axis=0)\n",
    "\n",
    "# 25. U-II Natural Gypsum in Activated Gypsum\n",
    "sum_uii_natural_gypsum = sheet.loc[named_range['U-II Natural Gypsum in Activated Gypsum'], dates].sum(axis=0)\n",
    "\n",
    "# 26. U-II Limestone in Activated Gypsum\n",
    "sum_uii_limestone_gypsum = sheet.loc[named_range['U-II Limestone in Activated Gypsum'], dates].sum(axis=0)\n",
    "\n",
    "# 27. U-I Conditioned ash\n",
    "sum_ui_conditioned_ash = sheet.loc[named_range['U-I Conditioned ash'], dates].sum(axis=0)\n",
    "\n",
    "# 28. U-I Dry Ash\n",
    "sum_ui_dry_ash = sheet.loc[named_range['U-I Dry Ash'], dates].sum(axis=0)\n",
    "\n",
    "# 29. U-II Conditioned ash\n",
    "sum_uii_conditioned_ash = sheet.loc[named_range['U-II Conditioned ash'], dates].sum(axis=0)\n",
    "\n",
    "# 30. U-II Dry Ash\n",
    "sum_uii_dry_ash = sheet.loc[named_range['U-II Dry Ash'], dates].sum(axis=0)\n",
    "\n",
    "# 31. Ext Clk Fresh U-I\n",
    "sum_ext_clk_fresh_ui = sheet.loc[named_range['Ext Clk Fresh U-I'], dates].sum(axis=0)\n",
    "\n",
    "# 32. Ext Clk Fresh U-II\n",
    "sum_ext_clk_fresh_uii = sheet.loc[named_range['Ext Clk Fresh U-II'], dates].sum(axis=0)\n",
    "\n",
    "# 33. Ext Clk old U-I\n",
    "sum_ext_clk_old_ui = sheet.loc[named_range['Ext Clk old U-I'], dates].sum(axis=0)\n",
    "\n",
    "# 34. Ext Clk old U-II\n",
    "sum_ext_clk_old_uii = sheet.loc[named_range['Ext Clk old U-II'], dates].sum(axis=0)\n",
    "\n",
    "# avg_indian_coal_percent = (sum_heat_linkage_coal_heat_unit1+sum_total_heat_linkage_coal_unit2)/(sum_total_heat_unit1+sum_total_heat_unit2)\n",
    "# avg_open_mkt_coal_percent = (sum_open_mkt_coal_heat_unit1+sum_total_heat_open_mkt_coal_unit2)/(sum_total_heat_unit1+sum_total_heat_unit2)\n",
    "# avg_us_pet_coke_percent = (sum_imported_pc_heat_unit1+ sum_imported_us_pc_heat)/(sum_total_heat_unit1+sum_total_heat_unit2)\n",
    "avg_liq_afr_percent = (ui_liquid_afr_hcv_sumproduct+ui_liquid_afr_lcv_sumproduct+uii_liquid_afr_hcv_sumproduct+uii_liquid_afr_lcv_sumproduct)/(sum_total_heat_unit1+sum_total_heat_unit2)\n",
    "avg_solid_afr_percent = (solid_afr_ncv_arb_sumproduct)/(sum_total_heat_unit1+sum_total_heat_unit2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Imported US Pet Coke': ['U-II_Imported US Pet Coke_Heat'],\n",
       " 'Linkage Coal': ['U-II_Indian Coal Linkage_Heat',\n",
       "  'U-I_Indian Coal Linkage_Heat'],\n",
       " 'Indian Pet Coke': ['U-II_Indian Pet Coke_Heat'],\n",
       " 'Open Mkt Coal': ['U-II_Open Market Coal_Heat', 'U-I_Open Market Coal_Heat'],\n",
       " 'Imported Pet Coke': ['U-I_Saudi Pet Coke_Heat']}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------Fuel------------------------------------------------------\n",
    "fuel_percent = []\n",
    "for fuel in fuel_type_dict:\n",
    "    total_quant = 0\n",
    "    for unit_fuel in fuel_type_dict[fuel]:\n",
    "        total_quant = total_quant + fuel_sheet.loc[fuel_range[unit_fuel], dates].sum(axis=0)\n",
    "    fuel_percent.append({f'{fuel}': total_quant/(sum_total_heat_unit1+sum_total_heat_unit2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Imported US Pet Coke': 0.304786866384673},\n",
       " {'Linkage Coal': 0.07165062617920655},\n",
       " {'Indian Pet Coke': 0.2299157026448809},\n",
       " {'Open Mkt Coal': 0.30284192994828124},\n",
       " {'Imported Pet Coke': 0.021671459093636086}]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dictionary with all the results\n",
    "# results = {\n",
    "#     'Increase Flyash in PPC': incr_flyash_ppc,\n",
    "#     'Increase Flyash in DT': incr_flyash_dt,\n",
    "#     'Increase Flyash in AW': incr_flyash_aw,\n",
    "#     'Alternate Gypsum Usage': alternate_gypsum_usage,\n",
    "#     'Conditioned Ash Usage': conditioned_ash_usage,\n",
    "#     'PI Addition in OPC': pi_addition_opc,\n",
    "#     'Avg Imported US Pet Coke CV': avg_imported_us_pc_cv,\n",
    "#     'U-II Imported US Pet Coke %': percentage_imported_us_pc_heat,\n",
    "#     'Avg Indian Coal (Linkage) CV U-II': avg_linkage_coal_unit2_cv,\n",
    "#     'U-II Indian Coal (Linkage) %': percentage_linkage_coal_unit2,\n",
    "#     'Avg Open Market Coal CV U-II': avg_open_mkt_coal_unit2_cv,\n",
    "#     'U-II Total Open Market Coal %': percentage_open_mkt_coal_unit2,\n",
    "#     'Avg Imported PC CV U-I': avg_imported_pc_unit1_cv,\n",
    "#     'U-I Imported PC %': percentage_imported_pc_unit1,\n",
    "#     'Avg Indian Coal Linkage CV U-I': avg_linkage_coal_unit1_cv,\n",
    "#     'U-I Indian Coal Linkage %': percentage_linkage_coal_unit1,\n",
    "#     'Avg Open Market Coal CV U-I': avg_open_mkt_coal_unit1_cv,\n",
    "#     'U-I Total Open Market Coal %': percentage_open_mkt_coal_unit1,\n",
    "#     'Unit 1: Specific Heat': avg_unit1_specific_heat,\n",
    "#     'Unit 2: Specific Heat': avg_unit2_specific_heat,\n",
    "#     'Unit 1 WHRS Generation': sum_line1_whrs_gen,\n",
    "#     'Unit 1 Kiln WHRS Generation': kiln1_whrs_gen,\n",
    "#     'Unit 2 WHRS Generation': sum_line2_whrs_gen,\n",
    "#     'Unit 2 Kiln WHRS Generation': kiln2_whrs_gen,\n",
    "#     'WHRS Gross Generation': sum_whrs_gross_gen,\n",
    "#     'Kiln 1 & 2 WHRS Generation': sum_kiln1_and_2_whrs_gen\n",
    "# }\n",
    "\n",
    "# # Create a DataFrame from the results dictionary\n",
    "# results_df = pd.DataFrame(list(results.items()), columns=['Metric', 'Value'])\n",
    "\n",
    "# # Write the DataFrame to an Excel file\n",
    "# output_path = 'D:/LLM/Electricity_Project/dashboard-automation-shared/results.xlsx'\n",
    "# results_df.to_excel(output_path, index=False)\n",
    "\n",
    "# print(f\"Results have been written to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "Udaan_Initiatives = result_sheet.range('A2:A27').value\n",
    "Baseline = result_sheet.range('C2:C27').value\n",
    "Initiatives = result_sheet.range('I:I').value\n",
    "Initiatives = [x for x in Initiatives if x is not None]\n",
    "Cost = result_sheet.range('K:K').value\n",
    "Cost = [x for x in Cost if x is not None]\n",
    "\n",
    "baseline_mapped_data = dict(zip(Udaan_Initiatives, Baseline))\n",
    "costing_mapped_data = dict(zip(Initiatives, Cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Initiatives', 'Clinker', 'Fly Ash', 'Conditioned Fly Ash', 'PI', 'Gypsum Natural', 'Activated gypsum', 'Bed Ash Gypsum', 'Cost other than HighS', 'Saudi Petcoke', 'Open market coal', 'Indigenious Coal', 'US petcoke', 'Fluid Petcoke', 'Sweetner Purchase', 'Own Sweetner', 'Purchase Limestone', 'Own Limestone', 'WHRS', 'Grid', 'Solar', 'Fuel Line-I', 'Fuel Line-II', 'Solid AFR', 'Liquid AFR', 'Phospho Gypsum', 'FGD Gypsum', 'Avg Heat', 'Power cost Line-I', 'Power cost Line-II', 'Avg Power Cost', 'Purchase RH Cost'])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costing_mapped_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mapped_data_header = {name: i + 2 for i, name in enumerate(baseline_mapped_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flyash_in_PPC = incr_flyash_ppc\n",
    "Flyash_in_DT = incr_flyash_dt\n",
    "Flyash_in_AW = incr_flyash_aw\n",
    "Conditioned_FA_PPC = conditioned_ash_usage\n",
    "PI_in_OPC = pi_addition_opc\n",
    "Activated_Gypsum = (sum_natural_gypsum_activated_gypsum + sum_limestone_activated_gypsum)/(sum_total_cement_production)\n",
    "Bed_Ash_Gypsum = sum_bed_ash_gypsum/sum_total_cement_production\n",
    "# Open_Mkt_Coal = avg_open_mkt_coal_percent\n",
    "# Indigenious_Coal = avg_indian_coal_percent\n",
    "# Imported_Petcoke = avg_us_pet_coke_percent\n",
    "Liquid_AFR = avg_liq_afr_percent\n",
    "Solid_AFR = avg_solid_afr_percent\n",
    "SHC_Line1 = avg_unit1_specific_heat\n",
    "SHC_Line2 = avg_unit2_specific_heat\n",
    "Sweetener = sweetener_weighted_avg\n",
    "Purchase_Limestone = purchase_weighted_avg\n",
    "Rehandling_Limestone = rehandling_weighted_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flyash_in_PPC_U1 = sum_line1_cement_champion_fa + sum_line1_cement_champion_plus_fa\n",
    "# Flyash_in_PPC_U2 = sum_line2_cement_champion_fa + sum_line2_cement_champion_plus_fa\n",
    "# Flyash_in_DT_U1 = sum_line1_cement_duratech_fa\n",
    "# Flyash_in_AW_U1 = sum_line1_cement_all_weather_fa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------Costing------------------------------------------------------\n",
    "Flyash_in_PPC_Cost = (Flyash_in_PPC-baseline_mapped_data['Flyash in Champion, +'])*(sum_cement_prod_ppc/sum_total_cement_production)*(costing_mapped_data['Clinker']-costing_mapped_data['Fly Ash'])\n",
    "Flyash_in_DT_Cost = (Flyash_in_DT-baseline_mapped_data['Flyash in Duratech'])*(sum_cement_prod_dt/sum_total_cement_production)*(costing_mapped_data['Clinker']-costing_mapped_data['Fly Ash'])\n",
    "Flyash_in_AW_Cost = (Flyash_in_AW-baseline_mapped_data['Flyash in All Weather'])*(sum_cement_prod_aw/sum_total_cement_production)*(costing_mapped_data['Clinker']-costing_mapped_data['Fly Ash'])\n",
    "\n",
    "\n",
    "cfa_ppc_sum_prod = (baseline_mapped_data['Flyash in Champion, +']*(sum_cement_prod_ppc/(sum_cement_prod_ppc + sum_cement_prod_dt + sum_cement_prod_aw)) + baseline_mapped_data['Flyash in Duratech']*(sum_cement_prod_dt/(sum_cement_prod_ppc + sum_cement_prod_dt + sum_cement_prod_aw)) + baseline_mapped_data['Flyash in All Weather']*(sum_cement_prod_aw/(sum_cement_prod_ppc + sum_cement_prod_dt + sum_cement_prod_aw)))*((sum_cement_prod_ppc+sum_cement_prod_dt+sum_cement_prod_aw)/sum_total_cement_production)\n",
    "Conditioned_FA_PPC_Cost = (Conditioned_FA_PPC-baseline_mapped_data['Conditional flyash in PPC'])*cfa_ppc_sum_prod*(costing_mapped_data['Fly Ash']-costing_mapped_data['Conditioned Fly Ash'])\n",
    "\n",
    "PI_in_OPC_Cost = (PI_in_OPC-baseline_mapped_data['PI in OPC'])*(sum_total_opc_production/sum_total_cement_production)*(costing_mapped_data['Clinker']-costing_mapped_data['PI'])\n",
    "Activated_Gypsum_Cost = (Activated_Gypsum-baseline_mapped_data['Activated Gypsum'])*((sum_cement_prod_ppc+sum_cement_prod_dt+sum_cement_prod_aw)/sum_total_cement_production)*(costing_mapped_data['Gypsum Natural']-costing_mapped_data['Activated gypsum'])\n",
    "Bed_Ash_Gypsum_Cost = (Bed_Ash_Gypsum-baseline_mapped_data['Bed Ash Gypsum (Alternate)'])*(costing_mapped_data['Gypsum Natural']-costing_mapped_data['Bed Ash Gypsum'])\n",
    "SHC_Line1_Cost = (baseline_mapped_data['Specific Heat Consumption Line I']-SHC_Line1)*(sum_clinker_prod_U1/sum_total_cement_production)*(costing_mapped_data['Fuel Line-I'])\n",
    "SHC_Line2_Cost = (baseline_mapped_data['Specific Heat Consumption Line II']-SHC_Line2)*(sum_clinker_prod_U2/sum_total_cement_production)*(costing_mapped_data['Fuel Line-II'])\n",
    "\n",
    "Sweetener_Cost = (baseline_mapped_data['Sweetener']-Sweetener)*((sum_clinker_prod_U1+sum_clinker_prod_U2)/(sum_total_cement_production))*(costing_mapped_data['Sweetner Purchase']-costing_mapped_data['Own Sweetner'])\n",
    "Purchase_Limestone_Cost = (baseline_mapped_data['Purchase Limestone']-Purchase_Limestone)*((sum_clinker_prod_U1+sum_clinker_prod_U2)/(sum_total_cement_production))*(costing_mapped_data['Purchase Limestone']-costing_mapped_data['Own Limestone'])\n",
    "Rehandling_Limestone_Cost = (baseline_mapped_data['Rehandling of Purchase Limestone']-Rehandling_Limestone)/sum_total_cement_production*(costing_mapped_data['Purchase RH Cost'])\n",
    "\n",
    "# Open_Mkt_Coal_Cost = (Open_Mkt_Coal-baseline_mapped_data['Open Market Coal'])*()\n",
    "\n",
    "\n",
    "\n",
    "# kiln1_whrs_gen\n",
    "# kiln2_whrs_gen\n",
    "# sum_kiln1_and_2_whrs_gen\n",
    "# sum_ui_natural_gypsum\n",
    "# sum_ui_limestone_gypsum\n",
    "# sum_uii_limestone_gypsum\n",
    "# sum_total_gypsum_usage\n",
    "# FGD_Gypsum_Gross = sum_fgd_gypsum\n",
    "# Bed_Ash_Gross = sum_bed_ash_gypsum\n",
    "# Natural_Gypsum_Line1 = sum_natural_gypsum_unit1\n",
    "# Natural_Gypsum_Line2 = sum_natural_gypsum_unit2\n",
    "# Conditioned_FA_Line1 = sum_ui_conditioned_ash\n",
    "# Conditioned_FA_Line2 = sum_uii_conditioned_ash\n",
    "# Conditioned_FA_Gross = sum_conditioned_ash_used\n",
    "\n",
    "# PI_OPC_Line1 = sum_line1_cement_opc_pi\n",
    "# PI_OPC_Line2 = sum_line2_cement_opc_pi\n",
    "\n",
    "# Specific_Heat_Consumption_Line1 = avg_unit1_specific_heat\n",
    "# Specific_Heat_Consumption_Line2 = avg_unit2_specific_heat\n",
    "# Specific_Heat_Consumption_Gross = (sum_total_heat_unit1+sum_total_heat_unit2)/(sum_clinker_prod_U1+ sum_clinker_prod_U2)\n",
    "# Clinker_Production_Line1 = sum_clinker_prod_U1\n",
    "# Clinker_Production_Line2 = sum_clinker_prod_U2\n",
    "# Clinker_Production_Gross = Clinker_Production_Line1 + Clinker_Production_Line2\n",
    "# Solid_AFR = sum_solid_afr_feeding\n",
    "# Liquid_AFR_Line1 = ui_liquid_afr_tons_total\n",
    "# Liquid_AFR_Line2 = uii_liquid_afr_tons_total\n",
    "# Indian_Coal_Percent = avg_indian_coal_percent\n",
    "# Open_Mkt_Coal_Percent = avg_open_mkt_coal_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding values\n",
    "actual_kpi_values = {\n",
    "    'Flyash in Champion, +': Flyash_in_PPC,\n",
    "    'Flyash in Duratech': Flyash_in_DT,\n",
    "    'Flyash in All Weather': Flyash_in_AW,\n",
    "    'Conditional flyash in PPC': Conditioned_FA_PPC,\n",
    "    'PI in OPC': PI_in_OPC,\n",
    "    'Activated Gypsum': Activated_Gypsum,\n",
    "    'Bed Ash Gypsum (Alternate)': Bed_Ash_Gypsum,\n",
    "    # 'Open Market Coal': Open_Mkt_Coal,\n",
    "    # 'Indigenious Coal': Indigenious_Coal,\n",
    "    # 'US Petcoke': Imported_Petcoke,\n",
    "    'Liquid AFR': Liquid_AFR,\n",
    "    'Solid AFR': Solid_AFR,\n",
    "    'Specific Heat Consumption Line I': SHC_Line1,\n",
    "    'Specific Heat Consumption Line II': SHC_Line2,\n",
    "    'Sweetener': Sweetener,\n",
    "    'Purchase Limestone': Purchase_Limestone,\n",
    "    'Rehandling of Purchase Limestone': Rehandling_Limestone\n",
    "}\n",
    "\n",
    "\n",
    "# Corresponding values\n",
    "exp_values = {\n",
    "    'Flyash in Champion, +': Flyash_in_PPC_Cost,\n",
    "    'Flyash in Duratech': Flyash_in_DT_Cost,\n",
    "    'Flyash in All Weather': Flyash_in_AW_Cost,\n",
    "    'Conditional flyash in PPC': Conditioned_FA_PPC_Cost,\n",
    "    'PI in OPC': PI_in_OPC_Cost,\n",
    "    'Activated Gypsum': Activated_Gypsum_Cost,\n",
    "    'Bed Ash Gypsum (Alternate)': Bed_Ash_Gypsum_Cost,\n",
    "    # 'Open Market Coal': Open_Mkt_Coal,\n",
    "    # 'Indigenious Coal': Indigenious_Coal,\n",
    "    # 'US Petcoke': US_Petcoke,\n",
    "    # 'Liquid AFR': Liquid_AFR,\n",
    "    # 'Solid AFR': Solid_AFR,\n",
    "    'Specific Heat Consumption Line I': SHC_Line1_Cost,\n",
    "    'Specific Heat Consumption Line II': SHC_Line2_Cost,\n",
    "    'Sweetener': Sweetener_Cost,\n",
    "    'Purchase Limestone': Purchase_Limestone_Cost,\n",
    "    'Rehandling of Purchase Limestone': Rehandling_Limestone_Cost\n",
    "}\n",
    "\n",
    "# Function to apply the operation to all variables\n",
    "\n",
    "def update_excel_cells(sheet, dictionary, values, column):\n",
    "    for key in values:\n",
    "        # Dynamically apply the values\n",
    "        sheet.range(f'{column}{dictionary[key]}').value = values[key]\n",
    "\n",
    "# Assuming 'sheet' is an object from xlwings representing the Excel sheet\n",
    "# update_excel_cells(sheet, baseline_mapped_data_header, values)\n",
    "\n",
    "update_excel_cells(result_sheet, baseline_mapped_data_header, actual_kpi_values, 'D')\n",
    "update_excel_cells(result_sheet, baseline_mapped_data_header, exp_values, 'E')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Imported US Pet Coke': 0.304786866384673},\n",
       " {'Linkage Coal': 0.07165062617920655},\n",
       " {'Indian Pet Coke': 0.2299157026448809},\n",
       " {'Open Mkt Coal': 0.30284192994828124},\n",
       " {'Imported Pet Coke': 0.021671459093636086}]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for item in fuel_percent:\n",
    "    key = list(item.keys())[0]\n",
    "    value = list(item.values())[0]\n",
    "    result_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (key, value) in enumerate(result_dict.items()):\n",
    "    result_sheet.range(f'A{i+32}').value = key\n",
    "    result_sheet.range(f'D{i+32}').value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Imported US Pet Coke', 'Linkage Coal', 'Indian Pet Coke', 'Open Mkt Coal', 'Imported Pet Coke'])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuel_type_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Initiatives', 'Clinker', 'Fly Ash', 'Conditioned Fly Ash', 'PI', 'Gypsum Natural', 'Activated gypsum', 'Bed Ash Gypsum', 'Cost other than HighS', 'Saudi Petcoke', 'Open market coal', 'Indigenious Coal', 'US petcoke', 'Fluid Petcoke', 'Sweetner Purchase', 'Own Sweetner', 'Purchase Limestone', 'Own Limestone', 'WHRS', 'Grid', 'Solar', 'Fuel Line-I', 'Fuel Line-II', 'Solid AFR', 'Liquid AFR', 'Phospho Gypsum', 'FGD Gypsum', 'Avg Heat', 'Power cost Line-I', 'Power cost Line-II', 'Avg Power Cost', 'Purchase RH Cost'])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costing_mapped_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "fuel_costing_prompt=PromptTemplate(\n",
    "            input_variables=[\"assumptions\", \"fuel_costing\", \"fuel_type\"],\n",
    "            template=\"\"\"\n",
    "            Based on given assumptions:\n",
    "            {assumptions}\n",
    "\n",
    "            Link the fuel costing with fuel type\n",
    "\n",
    "            fuel costings are:\n",
    "            {fuel_costing}\n",
    "\n",
    "            fuel type are:\n",
    "            {fuel_type}\n",
    "\n",
    "            Output the JSON with key as fuel type and value as fuel costing. Don't assume anything by yourself. Just use the given data.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "fuel_costing_chain = fuel_costing_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "assumptions = [\n",
    "    \"Indigenious coal and Linkage coal is same\",\n",
    "    \"Imported US Pet Coke is US petcoke\",\n",
    "    \"Imported PC is Saudi Petcoke\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Imported US Pet Coke': ['US petcoke'],\n",
       " 'Linkage Coal': ['Indigenious Coal'],\n",
       " 'Indian Pet Coke': ['Fluid Petcoke'],\n",
       " 'Open Mkt Coal': ['Open market coal'],\n",
       " 'Imported Pet Coke': ['Saudi Petcoke']}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_fuel = fuel_costing_chain.invoke({\"assumptions\": assumptions, \"fuel_costing\": costing_mapped_data.keys(), \"fuel_type\": fuel_type_dict.keys()})\n",
    "classified_fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
